{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jp_word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irasin/jp_w2v/blob/master/jp_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYMnT0H1n3C",
        "colab_type": "text"
      },
      "source": [
        "## Google Colabの使い方\n",
        "\n",
        "\n",
        "\n",
        "*   各ブロックにコードやmarkdown形式のテキストデータが記されている\n",
        "*   各ブロックの左側の開始ボタンを押すか、クリックしてshift+enterを同時に押すかでブロックを実行できる\n",
        "\n",
        "詳しく知りたい人は、次のページを参照してください\n",
        "\n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
        "\n",
        "https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935\n",
        "\n",
        "https://qiita.com/shoji9x9/items/0ff0f6f603df18d631ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwDrgtYKul1b",
        "colab_type": "text"
      },
      "source": [
        "## Chainerのバージョンを更新\n",
        "最初に実行するとき、下記のようなWARNINGが出現したら、`ランタイム/ランタイムを再起動`を選んで、再起動する。\n",
        "\n",
        "\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "\n",
        " 　 [typing]\n",
        "\n",
        "You must restart the runtime in order to use newly installed versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPiXy5QTQct9",
        "colab_type": "code",
        "outputId": "2add065b-6d78-42e0-dfc8-b18183ecd47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install -U chainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: chainer in /usr/local/lib/python3.6/dist-packages (6.3.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from chainer) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: protobuf<3.8.0rc1,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: typing<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txhc4yN3vYF3",
        "colab_type": "text"
      },
      "source": [
        "## GPUが使えるように、対応するCupyのバージョンを更新"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOqkfVednNli",
        "colab_type": "code",
        "outputId": "164371ba-2e31-4100-b2f2-f7bb24b70b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install 'cupy-cuda100>=6.2.0,<7.0.0'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cupy-cuda100<7.0.0,>=6.2.0 in /usr/local/lib/python3.6/dist-packages (6.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.12.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (0.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQut4q1CvxpN",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vecの実装\n",
        "\n",
        "下記のブロックを実行する際に、Cupyのバージョンが合わないエラーが出たら、上記のCupyの更新をもう一度実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieQ1Q94gQWc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "import os\n",
        "import six\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer.backends import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.initializers as I\n",
        "import chainer.links as L\n",
        "import chainer.optimizers as O\n",
        "from chainer import reporter\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "\n",
        "\n",
        "class ContinuousBoW(chainer.Chain):\n",
        "    \"\"\"Definition of Continuous Bag of Words Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(ContinuousBoW, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        e = self.embed(contexts)\n",
        "        h = F.sum(e, axis=1) * (1. / contexts.shape[1])\n",
        "        loss = self.loss_func(h, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SkipGram(chainer.Chain):\n",
        "    \"\"\"Definition of Skip-gram Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(SkipGram, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        e = self.embed(contexts)\n",
        "        batch_size, n_context, n_units = e.shape\n",
        "        x = F.broadcast_to(x[:, None], (batch_size, n_context))\n",
        "        e = F.reshape(e, (batch_size * n_context, n_units))\n",
        "        x = F.reshape(x, (batch_size * n_context,))\n",
        "        loss = self.loss_func(e, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SoftmaxCrossEntropyLoss(chainer.Chain):\n",
        "    \"\"\"Softmax cross entropy loss function preceded by linear transformation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(SoftmaxCrossEntropyLoss, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.out = L.Linear(n_in, n_out, initialW=0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return F.softmax_cross_entropy(self.out(x), t)\n",
        "\n",
        "\n",
        "class WindowIterator(chainer.dataset.Iterator):\n",
        "    \"\"\"Dataset iterator to create a batch of sequences at different positions.\n",
        "    This iterator returns a pair of the current words and the context words.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, window, batch_size, repeat=True):\n",
        "        self.dataset = np.array(dataset, np.int32)\n",
        "        self.window = window  # size of context window\n",
        "        self.batch_size = batch_size\n",
        "        self._repeat = repeat\n",
        "        # order is the array which is shuffled ``[window, window + 1, ...,\n",
        "        # len(dataset) - window - 1]``\n",
        "        self.order = np.random.permutation(\n",
        "            len(dataset) - window * 2).astype(np.int32)\n",
        "        self.order += window\n",
        "        self.current_position = 0\n",
        "        # Number of completed sweeps over the dataset. In this case, it is\n",
        "        # incremented if every word is visited at least once after the last\n",
        "        # increment.\n",
        "        self.epoch = 0\n",
        "        # True if the epoch is incremented at the last iteration.\n",
        "        self.is_new_epoch = False\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"This iterator returns a list representing a mini-batch.\n",
        "        Each item indicates a different position in the original sequence.\n",
        "        \"\"\"\n",
        "        if not self._repeat and self.epoch > 0:\n",
        "            raise StopIteration\n",
        "\n",
        "        i = self.current_position\n",
        "        i_end = i + self.batch_size\n",
        "        position = self.order[i:i_end]\n",
        "        w = np.random.randint(self.window - 1) + 1\n",
        "        offset = np.concatenate([np.arange(-w, 0), np.arange(1, w + 1)])\n",
        "        pos = position[:, None] + offset[None, :]\n",
        "        contexts = self.dataset.take(pos)\n",
        "        center = self.dataset.take(position)\n",
        "\n",
        "        if i_end >= len(self.order):\n",
        "            np.random.shuffle(self.order)\n",
        "            self.epoch += 1\n",
        "            self.is_new_epoch = True\n",
        "            self.current_position = 0\n",
        "        else:\n",
        "            self.is_new_epoch = False\n",
        "            self.current_position = i_end\n",
        "\n",
        "        return center, contexts\n",
        "\n",
        "    @property\n",
        "    def epoch_detail(self):\n",
        "        return self.epoch + float(self.current_position) / len(self.order)\n",
        "\n",
        "    def serialize(self, serializer):\n",
        "        self.current_position = serializer('current_position',\n",
        "                                           self.current_position)\n",
        "        self.epoch = serializer('epoch', self.epoch)\n",
        "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
        "        if self.order is not None:\n",
        "            serializer('order', self.order)\n",
        "\n",
        "\n",
        "@chainer.dataset.converter()\n",
        "def convert(batch, device):\n",
        "    center, contexts = batch\n",
        "    center = device.send(center)\n",
        "    contexts = device.send(contexts)\n",
        "    return center, contexts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI7xfi4HwKGE",
        "colab_type": "text"
      },
      "source": [
        "## Google Driveの認証\n",
        "実行した後、認証用のリンクがあるので、自分のGoogleアカウントで認証してください。\n",
        "認証コードを下のブランクに貼って確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwCEttjHtWoj",
        "colab_type": "code",
        "outputId": "03d3fff6-6817-427a-8651-7b4685dbc519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPo2f-DAwq-5",
        "colab_type": "text"
      },
      "source": [
        "## 自分のドライブの中身を確認する\n",
        "\n",
        "tokenized_data.txtがあるはず\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlXROB3EtkZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l drive/My\\ Drive/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUT_DBTw6ww",
        "colab_type": "text"
      },
      "source": [
        "## tokenized_data.txtに対して、Word2Vecの学習を行うための前処理を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOjjt87cQrs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/tokenized_data.txt', 'r') as f:\n",
        "    data = f.read().split()\n",
        "\n",
        "import collections\n",
        "\n",
        "index2word = {}\n",
        "word2index = {}\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for w in set(data):\n",
        "    word2index[w] = idx\n",
        "    index2word[idx] = w\n",
        "    idx += 1\n",
        "\n",
        "data_array = []\n",
        "\n",
        "for w in data:\n",
        "    data_array.append(word2index[w])\n",
        "\n",
        "data_array = np.array(data_array, dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyOi4YhioJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the dataset\n",
        "train = data_array[:]\n",
        "\n",
        "counts = collections.Counter(train)\n",
        "n_vocab = max(train) + 1\n",
        "\n",
        "vocab = word2index  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG4Gw9hjxJ5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--device', '-d', type=str, default='0',\n",
        "                    help='Device specifier. Either ChainerX device '\n",
        "                    'specifier or an integer. If non-negative integer, '\n",
        "                    'CuPy arrays with specified device id are used. If '\n",
        "                    'negative integer, NumPy arrays are used')\n",
        "parser.add_argument('--unit', '-u', default=200, type=int,\n",
        "                    help='number of units')\n",
        "parser.add_argument('--window', '-w', default=10, type=int,\n",
        "                    help='window size')\n",
        "parser.add_argument('--batchsize', '-b', type=int, default=1000,\n",
        "                    help='learning minibatch size')\n",
        "parser.add_argument('--epoch', '-e', default=3, type=int,\n",
        "                    help='number of epochs to learn')\n",
        "parser.add_argument('--model', '-m', choices=['skipgram', 'cbow'],\n",
        "                    default='skipgram',\n",
        "                    help='model type (\"skipgram\", \"cbow\")')\n",
        "parser.add_argument('--negative-size', default=5, type=int,\n",
        "                    help='number of negative samples')\n",
        "parser.add_argument('--out-type', '-o', choices=['hsm', 'ns', 'original'],\n",
        "                    default='hsm',\n",
        "                    help='output model type (\"hsm\": hierarchical softmax, '\n",
        "                    '\"ns\": negative sampling, \"original\": '\n",
        "                    'no approximation)')\n",
        "parser.add_argument('--out', default='result',\n",
        "                    help='Directory to output the result')\n",
        "group = parser.add_argument_group('deprecated arguments')\n",
        "group.add_argument('--gpu', '-g', dest='device',\n",
        "                   type=int, nargs='?', const=0,\n",
        "                   help='GPU ID (negative value indicates CPU)')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "if chainer.get_dtype() == np.float16:\n",
        "    warnings.warn(\n",
        "        'This example may cause NaN in FP16 mode.', RuntimeWarning)\n",
        "\n",
        "device = chainer.get_device(args.device)\n",
        "device.use()\n",
        "\n",
        "    \n",
        "print('Device: {}'.format(device))\n",
        "print('# unit: {}'.format(args.unit))\n",
        "print('Window: {}'.format(args.window))\n",
        "print('Minibatch-size: {}'.format(args.batchsize))\n",
        "print('# epoch: {}'.format(args.epoch))\n",
        "print('Training model: {}'.format(args.model))\n",
        "print('Output type: {}'.format(args.out_type))\n",
        "print('')\n",
        "\n",
        "print('n_vocab: %d' % n_vocab)\n",
        "print('data length: %d' % len(train))\n",
        "\n",
        "if args.out_type == 'hsm':\n",
        "    HSM = L.BinaryHierarchicalSoftmax\n",
        "    tree = HSM.create_huffman_tree(counts)\n",
        "    loss_func = HSM(args.unit, tree)\n",
        "    loss_func.W.array[...] = 0   \n",
        "elif args.out_type == 'ns':\n",
        "    cs = [counts[w] for w in range(len(counts))]\n",
        "    loss_func = L.NegativeSampling(args.unit, cs, args.negative_size)\n",
        "    loss_func.W.array[...] = 0\n",
        "elif args.out_type == 'original':\n",
        "    loss_func = SoftmaxCrossEntropyLoss(args.unit, n_vocab)\n",
        "else:\n",
        "    raise Exception('Unknown output type: {}'.format(args.out_type))\n",
        "\n",
        "# Choose the model\n",
        "if args.model == 'skipgram':\n",
        "    model = SkipGram(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "elif args.model == 'cbow':\n",
        "    model = ContinuousBoW(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "else:\n",
        "    raise Exception('Unknown model type: {}'.format(args.model))\n",
        "\n",
        "model.to_device(device)\n",
        "\n",
        "# Set up an optimizer\n",
        "optimizer = O.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "# Set up an iterator\n",
        "train_iter = WindowIterator(train, args.window, args.batchsize)\n",
        "\n",
        "\n",
        "# Set up an updater\n",
        "updater = training.updaters.StandardUpdater(\n",
        "    train_iter, optimizer, converter=convert, device=device)\n",
        "\n",
        "# Set up a trainer\n",
        "trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss']))\n",
        "trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "trainer.run()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjO0mN9qxY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the word2vec model\n",
        "with open('word2vec.model', 'w') as f:\n",
        "    f.write('%d %d\\n' % (len(index2word), args.unit))\n",
        "    w = cuda.to_cpu(model.embed.W.array)\n",
        "    for i, wi in enumerate(w):\n",
        "        v = ' '.join(map(str, wi))\n",
        "        f.write('%s %s\\n' % (index2word[i], v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GesyhM4LzEMu",
        "colab_type": "text"
      },
      "source": [
        "## word2vec.modelの存在を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_djicwTR5gK",
        "colab_type": "code",
        "outputId": "65f76f15-83df-40ed-9102-52db034fb6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls -l "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwx------ 3 root root 4096 Aug 27 15:32 drive\n",
            "drwxr-xr-x 2 root root 4096 Aug 27 15:53 result\n",
            "drwxr-xr-x 1 root root 4096 Aug 22 16:14 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmVzaZWzL6f",
        "colab_type": "text"
      },
      "source": [
        "## 自分のGoogle Driveに学習済みのword2vec.modelを保存\n",
        "ここでもう一度認証をする必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlztTM9Y49xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr5TBDnN3w8_",
        "colab_type": "code",
        "outputId": "275149a4-1020-4930-9fce-e78f4e8ba588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'word2vec.model',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('word2vec.model', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 12y584VsWIJKxzDhN8tm2UdmmolDWFwqg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-0Gdegzgro",
        "colab_type": "text"
      },
      "source": [
        "## 学習済みのword2vec.modelを試してみる\n",
        "下記のコードはGoogle Driveからword2vec.modelをローカルにダウンロードして、test.pyを実行しても良い\n",
        "\n",
        "UserWarningは無視して大丈夫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td_qPsWo44ap",
        "colab_type": "code",
        "outputId": "fa162363-eb40-4d1e-a6a1-c150b74dffe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import logging\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "logging.root.setLevel(level=logging.INFO)\n",
        "\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('word2vec.model', binary=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-27 15:55:12,652 : INFO : loading projection weights from word2vec.model\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-08-27 15:56:26,444 : INFO : loaded (361995, 200) matrix from word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdxvI8pC5WBs",
        "colab_type": "code",
        "outputId": "eaa41b5d-7b39-48fe-b2f5-ad9960d57ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.most_similar(positive=[\"トヨタ\"], topn=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-27 15:56:26,452 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('レクサス', 0.694892406463623),\n",
              " ('日産', 0.6528947353363037),\n",
              " ('フォルクスワーゲン', 0.612214982509613),\n",
              " ('スバル', 0.60957932472229),\n",
              " ('四輪駆動', 0.5998426079750061),\n",
              " ('軽自動車', 0.5913006663322449),\n",
              " ('軽トールワゴン', 0.5863284468650818),\n",
              " ('大衆車', 0.574801504611969),\n",
              " ('ダットサン', 0.5716363191604614),\n",
              " ('マツダ', 0.5654223561286926)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXRlL2lrkEd",
        "colab_type": "code",
        "outputId": "31845fb2-5553-4c50-c00b-2de96d587ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"声優\"], topn=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('俳優', 0.7191715836524963),\n",
              " ('タレント', 0.6951994895935059),\n",
              " ('ナレーター', 0.6850898861885071),\n",
              " ('脚本家', 0.679742693901062),\n",
              " ('女優', 0.663958728313446),\n",
              " ('歌手', 0.6222456693649292),\n",
              " ('演出家', 0.6194756627082825),\n",
              " ('お笑い芸人', 0.6088293194770813),\n",
              " ('お笑いタレント', 0.6038094758987427),\n",
              " ('ナレーション', 0.6016545295715332)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPathTmH5xji",
        "colab_type": "code",
        "outputId": "1d499948-6797-4557-b12f-bd4d03959187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"Python\"], topn=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('C言語', 0.7220237255096436),\n",
              " ('C++', 0.6927701234817505),\n",
              " ('プログラミング言語', 0.6915198564529419),\n",
              " ('ライブラリ', 0.6501110792160034),\n",
              " ('実装', 0.6467259526252747),\n",
              " ('インタプリタ', 0.6447563171386719),\n",
              " ('Java', 0.6375324726104736),\n",
              " ('JavaScript', 0.6313003301620483),\n",
              " ('ONC', 0.6309704184532166),\n",
              " ('RPC', 0.6260931491851807)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFan2gLI5zgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}