{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jp_word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irasin/jp_w2v/blob/master/jp_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYMnT0H1n3C",
        "colab_type": "text"
      },
      "source": [
        "## Google Colabの使い方\n",
        "\n",
        "\n",
        "\n",
        "*   各ブロックにコードやmarkdown形式のテキストデータが記されている\n",
        "*   各ブロックの左側の開始ボタンを押すか、クリックしてshift+enterを同時に押すかでブロックを実行できる\n",
        "\n",
        "詳しく知りたい人は、次のページを参照してください\n",
        "\n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
        "\n",
        "https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935\n",
        "\n",
        "https://qiita.com/shoji9x9/items/0ff0f6f603df18d631ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwDrgtYKul1b",
        "colab_type": "text"
      },
      "source": [
        "## Chainerのバージョンを更新\n",
        "最初に実行するとき、下記のようなWARNINGが出現したら、`ランタイム/ランタイムを再起動`を選んで、再起動する。\n",
        "\n",
        "\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "\n",
        " 　 [typing]\n",
        "\n",
        "You must restart the runtime in order to use newly installed versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPiXy5QTQct9",
        "colab_type": "code",
        "outputId": "cba6dac8-0e9c-4a9e-cd45-1d9365389243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install -U chainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: chainer in /usr/local/lib/python3.6/dist-packages (6.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf<3.8.0rc1,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from chainer) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typing<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txhc4yN3vYF3",
        "colab_type": "text"
      },
      "source": [
        "## GPUが使えるように、対応するCupyのバージョンを更新"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOqkfVednNli",
        "colab_type": "code",
        "outputId": "7010bc42-688e-4d13-d0dc-6dbaf5eee73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install 'cupy-cuda100>=6.2.0,<7.0.0'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cupy-cuda100<7.0.0,>=6.2.0 in /usr/local/lib/python3.6/dist-packages (6.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.12.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (0.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQut4q1CvxpN",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vecの実装\n",
        "\n",
        "下記のブロックを実行する際に、Cupyのバージョンが合わないエラーが出たら、上記のCupyの更新をもう一度実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieQ1Q94gQWc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "import os\n",
        "import six\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer.backends import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.initializers as I\n",
        "import chainer.links as L\n",
        "import chainer.optimizers as O\n",
        "from chainer import reporter\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "\n",
        "\n",
        "class ContinuousBoW(chainer.Chain):\n",
        "    \"\"\"Definition of Continuous Bag of Words Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(ContinuousBoW, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        e = self.embed(contexts)\n",
        "        h = F.sum(e, axis=1) * (1. / contexts.shape[1])\n",
        "        loss = self.loss_func(h, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SkipGram(chainer.Chain):\n",
        "    \"\"\"Definition of Skip-gram Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(SkipGram, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        e = self.embed(contexts)\n",
        "        batch_size, n_context, n_units = e.shape\n",
        "        x = F.broadcast_to(x[:, None], (batch_size, n_context))\n",
        "        e = F.reshape(e, (batch_size * n_context, n_units))\n",
        "        x = F.reshape(x, (batch_size * n_context,))\n",
        "        loss = self.loss_func(e, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SoftmaxCrossEntropyLoss(chainer.Chain):\n",
        "    \"\"\"Softmax cross entropy loss function preceded by linear transformation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(SoftmaxCrossEntropyLoss, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.out = L.Linear(n_in, n_out, initialW=0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return F.softmax_cross_entropy(self.out(x), t)\n",
        "\n",
        "\n",
        "class WindowIterator(chainer.dataset.Iterator):\n",
        "    \"\"\"Dataset iterator to create a batch of sequences at different positions.\n",
        "    This iterator returns a pair of the current words and the context words.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, window, batch_size, repeat=True):\n",
        "        self.dataset = np.array(dataset, np.int32)\n",
        "        self.window = window  # size of context window\n",
        "        self.batch_size = batch_size\n",
        "        self._repeat = repeat\n",
        "        # order is the array which is shuffled ``[window, window + 1, ...,\n",
        "        # len(dataset) - window - 1]``\n",
        "        self.order = np.random.permutation(\n",
        "            len(dataset) - window * 2).astype(np.int32)\n",
        "        self.order += window\n",
        "        self.current_position = 0\n",
        "        # Number of completed sweeps over the dataset. In this case, it is\n",
        "        # incremented if every word is visited at least once after the last\n",
        "        # increment.\n",
        "        self.epoch = 0\n",
        "        # True if the epoch is incremented at the last iteration.\n",
        "        self.is_new_epoch = False\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"This iterator returns a list representing a mini-batch.\n",
        "        Each item indicates a different position in the original sequence.\n",
        "        \"\"\"\n",
        "        if not self._repeat and self.epoch > 0:\n",
        "            raise StopIteration\n",
        "\n",
        "        i = self.current_position\n",
        "        i_end = i + self.batch_size\n",
        "        position = self.order[i:i_end]\n",
        "        w = np.random.randint(self.window - 1) + 1\n",
        "        offset = np.concatenate([np.arange(-w, 0), np.arange(1, w + 1)])\n",
        "        pos = position[:, None] + offset[None, :]\n",
        "        contexts = self.dataset.take(pos)\n",
        "        center = self.dataset.take(position)\n",
        "\n",
        "        if i_end >= len(self.order):\n",
        "            np.random.shuffle(self.order)\n",
        "            self.epoch += 1\n",
        "            self.is_new_epoch = True\n",
        "            self.current_position = 0\n",
        "        else:\n",
        "            self.is_new_epoch = False\n",
        "            self.current_position = i_end\n",
        "\n",
        "        return center, contexts\n",
        "\n",
        "    @property\n",
        "    def epoch_detail(self):\n",
        "        return self.epoch + float(self.current_position) / len(self.order)\n",
        "\n",
        "    def serialize(self, serializer):\n",
        "        self.current_position = serializer('current_position',\n",
        "                                           self.current_position)\n",
        "        self.epoch = serializer('epoch', self.epoch)\n",
        "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
        "        if self.order is not None:\n",
        "            serializer('order', self.order)\n",
        "\n",
        "\n",
        "@chainer.dataset.converter()\n",
        "def convert(batch, device):\n",
        "    center, contexts = batch\n",
        "    center = device.send(center)\n",
        "    contexts = device.send(contexts)\n",
        "    return center, contexts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI7xfi4HwKGE",
        "colab_type": "text"
      },
      "source": [
        "## Google Driveの認証\n",
        "実行した後、認証用のリンクがあるので、自分のGoogleアカウントで認証してください。\n",
        "認証コードを下のブランクに貼って確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwCEttjHtWoj",
        "colab_type": "code",
        "outputId": "4b2c6a86-3b6a-4ade-aa2a-19fa277f8d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPo2f-DAwq-5",
        "colab_type": "text"
      },
      "source": [
        "## 自分のドライブの中身を確認する\n",
        "\n",
        "tokenized_data.txtがあるはず\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlXROB3EtkZx",
        "colab_type": "code",
        "outputId": "7d05493d-0680-430b-8d15-1974fee4935c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!ls -l drive/My\\ Drive/ "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 836831\n",
            "drwx------ 2 root root      4096 Jun  3 11:51  コンペ2018\n",
            "drwx------ 2 root root      4096 May 16 04:52  Avatar-Net-Pytorch\n",
            "-rw------- 1 root root     83492 Jul 21 11:35  c2v.ipynb\n",
            "drwx------ 2 root root      4096 Dec 14  2018 'Colab Notebooks'\n",
            "drwx------ 2 root root      4096 May 20  2018  miku\n",
            "-rw------- 1 root root   7132316 Aug  5 06:49  p1780-tang.pdf\n",
            "drwx------ 2 root root      4096 Aug  5 06:40  p2v_src\n",
            "drwx------ 2 root root      4096 May 20  2018  programming\n",
            "drwx------ 2 root root      4096 May 21 01:19  randd_eight_skill_prediction\n",
            "drwx------ 2 root root      4096 May  8 07:49  StyleTransfer\n",
            "drwx------ 2 root root      4096 Jan 15  2018  tex資料\n",
            "-rw------- 1 root root  57887962 Aug  6 15:03  tokenized_data.txt\n",
            "drwx------ 2 root root      4096 Jun 14 08:42  VISA更新\n",
            "-rw------- 1 root root  58070450 Aug  6 10:42  wiki50_tokenzied.txt\n",
            "-rw------- 1 root root 733469461 Aug  6 11:21  word2vec.model\n",
            "drwx------ 2 root root      4096 Feb 18 08:47  就活\n",
            "drwx------ 2 root root      4096 May 16 04:19  有価証券報告書関連論文\n",
            "drwx------ 2 root root      4096 May 20  2018  東工大講義\n",
            "-rw------- 1 root root    212394 Sep  9  2018  猫に必要なもの.pdf\n",
            "drwx------ 2 root root      4096 May  8  2018  論文・資料\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUT_DBTw6ww",
        "colab_type": "text"
      },
      "source": [
        "## tokenized_data.txtに対して、Word2Vecの学習を行うための前処理を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOjjt87cQrs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/tokenized_data.txt', 'r') as f:\n",
        "    data = f.read().split()\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "index2word = {}\n",
        "word2index = {}\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for w in set(data):\n",
        "    word2index[w] = idx\n",
        "    index2word[idx] = w\n",
        "    idx += 1\n",
        "\n",
        "data_array = []\n",
        "\n",
        "for w in data:\n",
        "    data_array.append(word2index[w])\n",
        "\n",
        "data_array = np.array(data_array, dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyOi4YhioJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the dataset\n",
        "train = data_array[:]\n",
        "\n",
        "counts = collections.Counter(train)\n",
        "n_vocab = max(train) + 1\n",
        "\n",
        "vocab = word2index  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG4Gw9hjxJ5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--device', '-d', type=str, default='0',\n",
        "                    help='Device specifier. Either ChainerX device '\n",
        "                    'specifier or an integer. If non-negative integer, '\n",
        "                    'CuPy arrays with specified device id are used. If '\n",
        "                    'negative integer, NumPy arrays are used')\n",
        "parser.add_argument('--unit', '-u', default=200, type=int,\n",
        "                    help='number of units')\n",
        "parser.add_argument('--window', '-w', default=10, type=int,\n",
        "                    help='window size')\n",
        "parser.add_argument('--batchsize', '-b', type=int, default=1000,\n",
        "                    help='learning minibatch size')\n",
        "parser.add_argument('--epoch', '-e', default=3, type=int,\n",
        "                    help='number of epochs to learn')\n",
        "parser.add_argument('--model', '-m', choices=['skipgram', 'cbow'],\n",
        "                    default='skipgram',\n",
        "                    help='model type (\"skipgram\", \"cbow\")')\n",
        "parser.add_argument('--negative-size', default=5, type=int,\n",
        "                    help='number of negative samples')\n",
        "parser.add_argument('--out-type', '-o', choices=['hsm', 'ns', 'original'],\n",
        "                    default='hsm',\n",
        "                    help='output model type (\"hsm\": hierarchical softmax, '\n",
        "                    '\"ns\": negative sampling, \"original\": '\n",
        "                    'no approximation)')\n",
        "parser.add_argument('--out', default='result',\n",
        "                    help='Directory to output the result')\n",
        "group = parser.add_argument_group('deprecated arguments')\n",
        "group.add_argument('--gpu', '-g', dest='device',\n",
        "                   type=int, nargs='?', const=0,\n",
        "                   help='GPU ID (negative value indicates CPU)')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "if chainer.get_dtype() == np.float16:\n",
        "    warnings.warn(\n",
        "        'This example may cause NaN in FP16 mode.', RuntimeWarning)\n",
        "\n",
        "device = chainer.get_device(args.device)\n",
        "device.use()\n",
        "\n",
        "    \n",
        "print('Device: {}'.format(device))\n",
        "print('# unit: {}'.format(args.unit))\n",
        "print('Window: {}'.format(args.window))\n",
        "print('Minibatch-size: {}'.format(args.batchsize))\n",
        "print('# epoch: {}'.format(args.epoch))\n",
        "print('Training model: {}'.format(args.model))\n",
        "print('Output type: {}'.format(args.out_type))\n",
        "print('')\n",
        "\n",
        "print('n_vocab: %d' % n_vocab)\n",
        "print('data length: %d' % len(train))\n",
        "\n",
        "if args.out_type == 'hsm':\n",
        "    HSM = L.BinaryHierarchicalSoftmax\n",
        "    tree = HSM.create_huffman_tree(counts)\n",
        "    loss_func = HSM(args.unit, tree)\n",
        "    loss_func.W.array[...] = 0   \n",
        "elif args.out_type == 'ns':\n",
        "    cs = [counts[w] for w in range(len(counts))]\n",
        "    loss_func = L.NegativeSampling(args.unit, cs, args.negative_size)\n",
        "    loss_func.W.array[...] = 0\n",
        "elif args.out_type == 'original':\n",
        "    loss_func = SoftmaxCrossEntropyLoss(args.unit, n_vocab)\n",
        "else:\n",
        "    raise Exception('Unknown output type: {}'.format(args.out_type))\n",
        "\n",
        "# Choose the model\n",
        "if args.model == 'skipgram':\n",
        "    model = SkipGram(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "elif args.model == 'cbow':\n",
        "    model = ContinuousBoW(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "else:\n",
        "    raise Exception('Unknown model type: {}'.format(args.model))\n",
        "\n",
        "model.to_device(device)\n",
        "\n",
        "# Set up an optimizer\n",
        "optimizer = O.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "# Set up an iterator\n",
        "train_iter = WindowIterator(train, args.window, args.batchsize)\n",
        "val_iter = WindowIterator(val, args.window, args.batchsize, repeat=False)\n",
        "\n",
        "# Set up an updater\n",
        "updater = training.updaters.StandardUpdater(\n",
        "    train_iter, optimizer, converter=convert, device=device)\n",
        "\n",
        "# Set up a trainer\n",
        "trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss', 'validation/main/loss']))\n",
        "trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "trainer.run()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjO0mN9qxY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the word2vec model\n",
        "with open('word2vec.model', 'w') as f:\n",
        "    f.write('%d %d\\n' % (len(index2word), args.unit))\n",
        "    w = cuda.to_cpu(model.embed.W.array)\n",
        "    for i, wi in enumerate(w):\n",
        "        v = ' '.join(map(str, wi))\n",
        "        f.write('%s %s\\n' % (index2word[i], v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GesyhM4LzEMu",
        "colab_type": "text"
      },
      "source": [
        "## word2vec.modelの存在を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_djicwTR5gK",
        "colab_type": "code",
        "outputId": "1e6445af-88e5-4a32-bd15-92144cae8f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls -l "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 828600\n",
            "drwx------ 3 root root      4096 Aug 10 09:01 drive\n",
            "drwxr-xr-x 2 root root      4096 Aug 10 09:19 result\n",
            "drwxr-xr-x 1 root root      4096 Aug  2 16:06 sample_data\n",
            "-rw-r--r-- 1 root root 848469987 Aug 10 09:20 word2vec.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmVzaZWzL6f",
        "colab_type": "text"
      },
      "source": [
        "## 自分のGoogle Driveに学習済みのword2vec.modelを保存\n",
        "ここでもう一度認証をする必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlztTM9Y49xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr5TBDnN3w8_",
        "colab_type": "code",
        "outputId": "83edf562-8744-4137-adba-ba0a63711e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'word2vec.model',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('word2vec.model', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1synbt6xY-Tp68yAYQV9PURBEM9p3yXoc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-0Gdegzgro",
        "colab_type": "text"
      },
      "source": [
        "## 学習済みのword2vec.modelを試してみる\n",
        "下記のコードはGoogle Driveからword2vec.modelをローカルにダウンロードして、test.pyを実行しても良い\n",
        "\n",
        "UserWarningは無視して大丈夫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td_qPsWo44ap",
        "colab_type": "code",
        "outputId": "643334d4-c4a0-43e4-af0a-a9e1441125f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import logging\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "logging.root.setLevel(level=logging.INFO)\n",
        "\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('word2vec.model', binary=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-10 09:21:17,215 : INFO : loading projection weights from word2vec.model\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-08-10 09:22:21,640 : INFO : loaded (361995, 200) matrix from word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdxvI8pC5WBs",
        "colab_type": "code",
        "outputId": "114b604f-fb1e-4584-a7a0-8b5c2e39cb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.most_similar(positive=[\"トヨタ\"], topn=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-10 09:22:23,760 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('レクサス', 0.7090200781822205),\n",
              " ('日産', 0.7048579454421997),\n",
              " ('スバル', 0.6470560431480408),\n",
              " ('軽自動車', 0.6420823335647583),\n",
              " ('四輪駆動', 0.6304976940155029),\n",
              " ('ダットサン', 0.6265804171562195),\n",
              " ('ブランド', 0.6081885695457458),\n",
              " ('4WD', 0.6024623513221741),\n",
              " ('高級車', 0.6004769802093506),\n",
              " ('フォルクスワーゲン', 0.5939617156982422)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXRlL2lrkEd",
        "colab_type": "code",
        "outputId": "98b3131d-b055-4cf9-e47c-dd2498fbf68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"声優\"], topn=10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('タレント', 0.7015098929405212),\n",
              " ('ナレーター', 0.6986377239227295),\n",
              " ('俳優', 0.6952576637268066),\n",
              " ('女優', 0.6380811333656311),\n",
              " ('脚本家', 0.6325925588607788),\n",
              " ('ラジオパーソナリティ', 0.6181122064590454),\n",
              " ('お笑い芸人', 0.6018644571304321),\n",
              " ('歌手', 0.5958029627799988),\n",
              " ('漫画家', 0.5934780836105347),\n",
              " ('ナレーション', 0.5912138223648071)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPathTmH5xji",
        "colab_type": "code",
        "outputId": "e9c1c2d7-838a-4c21-a8c7-f0c1480f5d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"Python\"], topn=10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('C言語', 0.7063682079315186),\n",
              " ('プログラミング言語', 0.6869475841522217),\n",
              " ('Java', 0.6586480736732483),\n",
              " ('型付き', 0.6450315713882446),\n",
              " ('HTML', 0.6415669918060303),\n",
              " ('ライブラリ', 0.6411113739013672),\n",
              " ('インタプリタ', 0.6388726234436035),\n",
              " ('Perl', 0.6275331377983093),\n",
              " ('C++', 0.6211255788803101),\n",
              " ('実装', 0.6199963092803955)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFan2gLI5zgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}