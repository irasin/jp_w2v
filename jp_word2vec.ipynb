{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jp_word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irasin/jp_w2v/blob/master/jp_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYMnT0H1n3C",
        "colab_type": "text"
      },
      "source": [
        "## Google Colabの使い方\n",
        "\n",
        "\n",
        "\n",
        "*   各ブロックにコードやmarkdown形式のテキストデータが記されている\n",
        "*   各ブロックの左側の開始ボタンを押すか、クリックしてshift+enterを同時に押すかでブロックを実行できる\n",
        "\n",
        "詳しく知りたい人は、次のページを参照してください\n",
        "\n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
        "\n",
        "https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935\n",
        "\n",
        "https://qiita.com/shoji9x9/items/0ff0f6f603df18d631ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwDrgtYKul1b",
        "colab_type": "text"
      },
      "source": [
        "## Chainerのバージョンを更新\n",
        "最初に実行するとき、下記のようなWARNINGが出現したら、`ランタイム/ランタイムを再起動`を選んで、再起動する。\n",
        "\n",
        "\n",
        "WARNING: The following packages were previously imported in this runtime:\n",
        "\n",
        " 　 [typing]\n",
        "\n",
        "You must restart the runtime in order to use newly installed versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPiXy5QTQct9",
        "colab_type": "code",
        "outputId": "38df4a43-aafa-4820-be0b-1283796b5293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install -U chainer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: chainer in /usr/local/lib/python3.6/dist-packages (6.3.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: protobuf<3.8.0rc1,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: typing<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from chainer) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txhc4yN3vYF3",
        "colab_type": "text"
      },
      "source": [
        "## GPUが使えるように、対応するCupyのバージョンを更新"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOqkfVednNli",
        "colab_type": "code",
        "outputId": "7098b8c3-979e-470c-e0a5-fd55e8b2c735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install 'cupy-cuda100>=6.2.0,<7.0.0'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cupy-cuda100<7.0.0,>=6.2.0 in /usr/local/lib/python3.6/dist-packages (6.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (1.16.4)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100<7.0.0,>=6.2.0) (0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQut4q1CvxpN",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vecの実装\n",
        "\n",
        "下記のブロックを実行する際に、Cupyのバージョンが合わないエラーが出たら、上記のCupyの更新をもう一度実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieQ1Q94gQWc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "import os\n",
        "import six\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer.backends import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.initializers as I\n",
        "import chainer.links as L\n",
        "import chainer.optimizers as O\n",
        "from chainer import reporter\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "\n",
        "\n",
        "# CBOWのクラスの定義\n",
        "class ContinuousBoW(chainer.Chain):\n",
        "    \"\"\"Definition of Continuous Bag of Words Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(ContinuousBoW, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            # 埋め込み層の定義\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        # フォワードでロスを計算\n",
        "        e = self.embed(contexts)\n",
        "        h = F.sum(e, axis=1) * (1. / contexts.shape[1])\n",
        "        loss = self.loss_func(h, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "# SkipGramのクラスの定義\n",
        "class SkipGram(chainer.Chain):\n",
        "    \"\"\"Definition of Skip-gram Model\"\"\"\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, loss_func):\n",
        "        super(SkipGram, self).__init__()\n",
        "\n",
        "        with self.init_scope():\n",
        "            # 埋め込み層の定義\n",
        "            self.embed = L.EmbedID(\n",
        "                n_vocab, n_units, initialW=I.Uniform(1. / n_units))\n",
        "            self.loss_func = loss_func\n",
        "\n",
        "    def forward(self, x, contexts):\n",
        "        # フォワードでロスを計算\n",
        "        e = self.embed(contexts)\n",
        "        batch_size, n_context, n_units = e.shape\n",
        "        x = F.broadcast_to(x[:, None], (batch_size, n_context))\n",
        "        e = F.reshape(e, (batch_size * n_context, n_units))\n",
        "        x = F.reshape(x, (batch_size * n_context,))\n",
        "        loss = self.loss_func(e, x)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "    \n",
        "# ソフトマックスクロスエントロピーのクラス\n",
        "# 線形層を挟む\n",
        "class SoftmaxCrossEntropyLoss(chainer.Chain):\n",
        "    \"\"\"Softmax cross entropy loss function preceded by linear transformation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(SoftmaxCrossEntropyLoss, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.out = L.Linear(n_in, n_out, initialW=0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return F.softmax_cross_entropy(self.out(x), t)\n",
        "\n",
        "    \n",
        "# データセットのイテレータ\n",
        "# 中心語と文脈語のペアを返す\n",
        "class WindowIterator(chainer.dataset.Iterator):\n",
        "    \"\"\"Dataset iterator to create a batch of sequences at different positions.\n",
        "    This iterator returns a pair of the current words and the context words.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, window, batch_size, repeat=True):\n",
        "        self.dataset = np.array(dataset, np.int32)\n",
        "        self.window = window  # size of context window\n",
        "        self.batch_size = batch_size\n",
        "        self._repeat = repeat\n",
        "        # order is the array which is shuffled ``[window, window + 1, ...,\n",
        "        # len(dataset) - window - 1]``\n",
        "        self.order = np.random.permutation(\n",
        "            len(dataset) - window * 2).astype(np.int32)\n",
        "        self.order += window\n",
        "        self.current_position = 0\n",
        "        # Number of completed sweeps over the dataset. In this case, it is\n",
        "        # incremented if every word is visited at least once after the last\n",
        "        # increment.\n",
        "        self.epoch = 0\n",
        "        # True if the epoch is incremented at the last iteration.\n",
        "        self.is_new_epoch = False\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"This iterator returns a list representing a mini-batch.\n",
        "        Each item indicates a different position in the original sequence.\n",
        "        \"\"\"\n",
        "        if not self._repeat and self.epoch > 0:\n",
        "            raise StopIteration\n",
        "\n",
        "        i = self.current_position\n",
        "        i_end = i + self.batch_size\n",
        "        position = self.order[i:i_end]\n",
        "        w = np.random.randint(self.window - 1) + 1\n",
        "        offset = np.concatenate([np.arange(-w, 0), np.arange(1, w + 1)])\n",
        "        pos = position[:, None] + offset[None, :]\n",
        "        contexts = self.dataset.take(pos)\n",
        "        center = self.dataset.take(position)\n",
        "\n",
        "        if i_end >= len(self.order):\n",
        "            np.random.shuffle(self.order)\n",
        "            self.epoch += 1\n",
        "            self.is_new_epoch = True\n",
        "            self.current_position = 0\n",
        "        else:\n",
        "            self.is_new_epoch = False\n",
        "            self.current_position = i_end\n",
        "\n",
        "        return center, contexts\n",
        "\n",
        "    @property\n",
        "    def epoch_detail(self):\n",
        "        return self.epoch + float(self.current_position) / len(self.order)\n",
        "\n",
        "    def serialize(self, serializer):\n",
        "        self.current_position = serializer('current_position',\n",
        "                                           self.current_position)\n",
        "        self.epoch = serializer('epoch', self.epoch)\n",
        "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
        "        if self.order is not None:\n",
        "            serializer('order', self.order)\n",
        "\n",
        "# 学習データを対応するデバイスに変換する関数\n",
        "@chainer.dataset.converter()\n",
        "def convert(batch, device):\n",
        "    center, contexts = batch\n",
        "    center = device.send(center)\n",
        "    contexts = device.send(contexts)\n",
        "    return center, contexts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI7xfi4HwKGE",
        "colab_type": "text"
      },
      "source": [
        "## Google Driveの認証\n",
        "実行した後、認証用のリンクがあるので、自分のGoogleアカウントで認証してください。\n",
        "認証コードを下のブランクに貼って確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwCEttjHtWoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPo2f-DAwq-5",
        "colab_type": "text"
      },
      "source": [
        "## 自分のドライブの中身を確認する\n",
        "\n",
        "tokenized_data.txtがあるはず\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlXROB3EtkZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l drive/My\\ Drive/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUT_DBTw6ww",
        "colab_type": "text"
      },
      "source": [
        "## tokenized_data.txtに対して、Word2Vecの学習を行うための前処理を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOjjt87cQrs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 分かち書き済みのデータを読み込む\n",
        "with open('drive/My Drive/tokenized_data.txt', 'r') as f:\n",
        "    data = f.read().split()\n",
        "\n",
        "import collections\n",
        "\n",
        "# 単語とindexの対応付け\n",
        "index2word = {}\n",
        "word2index = {}\n",
        "\n",
        "idx = 0\n",
        "for w in set(data):\n",
        "    word2index[w] = idx\n",
        "    index2word[idx] = w\n",
        "    idx += 1\n",
        "\n",
        "# 学習データの生成\n",
        "data_array = []\n",
        "\n",
        "for w in data:\n",
        "    data_array.append(word2index[w])\n",
        "\n",
        "# 学習データをnp.arrayの形式に変換\n",
        "data_array = np.array(data_array, dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyOi4YhioJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データセットのセットアップ\n",
        "train = data_array[:]\n",
        "\n",
        "counts = collections.Counter(train)\n",
        "n_vocab = max(train) + 1\n",
        "\n",
        "vocab = word2index  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG4Gw9hjxJ5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習用パラメータの設定\n",
        "parser = argparse.ArgumentParser()\n",
        "# 学習Device設定\n",
        "parser.add_argument('--device', '-d', type=str, default='0',\n",
        "                    help='Device specifier. Either ChainerX device '\n",
        "                    'specifier or an integer. If non-negative integer, '\n",
        "                    'CuPy arrays with specified device id are used. If '\n",
        "                    'negative integer, NumPy arrays are used')\n",
        "# 単語ベクトルの次元\n",
        "parser.add_argument('--unit', '-u', default=200, type=int,\n",
        "                    help='number of units')\n",
        "# ウインドサイズ\n",
        "parser.add_argument('--window', '-w', default=10, type=int,\n",
        "                    help='window size')\n",
        "# バッチサイズ\n",
        "parser.add_argument('--batchsize', '-b', type=int, default=1000,\n",
        "                    help='learning minibatch size')\n",
        "# 学習エポック数\n",
        "parser.add_argument('--epoch', '-e', default=3, type=int,\n",
        "                    help='number of epochs to learn')\n",
        "# モデル選択: CBOW/Skipgram\n",
        "parser.add_argument('--model', '-m', choices=['skipgram', 'cbow'],\n",
        "                    default='skipgram',\n",
        "                    help='model type (\"skipgram\", \"cbow\")')\n",
        "# ネガティブサンプリング際のサンプル数\n",
        "parser.add_argument('--negative-size', default=5, type=int,\n",
        "                    help='number of negative samples')\n",
        "# モデル学習方式: 階層ソフトマックス/ネガティブサンプリング/近似なし\n",
        "parser.add_argument('--out-type', '-o', choices=['hsm', 'ns', 'original'],\n",
        "                    default='hsm',\n",
        "                    help='output model type (\"hsm\": hierarchical softmax, '\n",
        "                    '\"ns\": negative sampling, \"original\": '\n",
        "                    'no approximation)')\n",
        "#　ログ保存先\n",
        "parser.add_argument('--out', default='result',\n",
        "                    help='Directory to output the result')\n",
        "group = parser.add_argument_group('deprecated arguments')\n",
        "# GPUID\n",
        "group.add_argument('--gpu', '-g', dest='device',\n",
        "                   type=int, nargs='?', const=0,\n",
        "                   help='GPU ID (negative value indicates CPU)')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "if chainer.get_dtype() == np.float16:\n",
        "    warnings.warn(\n",
        "        'This example may cause NaN in FP16 mode.', RuntimeWarning)\n",
        "\n",
        "device = chainer.get_device(args.device)\n",
        "device.use()\n",
        "\n",
        "    \n",
        "print('Device: {}'.format(device))\n",
        "print('# unit: {}'.format(args.unit))\n",
        "print('Window: {}'.format(args.window))\n",
        "print('Minibatch-size: {}'.format(args.batchsize))\n",
        "print('# epoch: {}'.format(args.epoch))\n",
        "print('Training model: {}'.format(args.model))\n",
        "print('Output type: {}'.format(args.out_type))\n",
        "print('')\n",
        "\n",
        "print('n_vocab: %d' % n_vocab)\n",
        "print('data length: %d' % len(train))\n",
        "\n",
        "if args.out_type == 'hsm':\n",
        "    HSM = L.BinaryHierarchicalSoftmax\n",
        "    tree = HSM.create_huffman_tree(counts)\n",
        "    loss_func = HSM(args.unit, tree)\n",
        "    loss_func.W.array[...] = 0   \n",
        "elif args.out_type == 'ns':\n",
        "    cs = [counts[w] for w in range(len(counts))]\n",
        "    loss_func = L.NegativeSampling(args.unit, cs, args.negative_size)\n",
        "    loss_func.W.array[...] = 0\n",
        "elif args.out_type == 'original':\n",
        "    loss_func = SoftmaxCrossEntropyLoss(args.unit, n_vocab)\n",
        "else:\n",
        "    raise Exception('Unknown output type: {}'.format(args.out_type))\n",
        "\n",
        "# モデル設定\n",
        "if args.model == 'skipgram':\n",
        "    model = SkipGram(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "elif args.model == 'cbow':\n",
        "    model = ContinuousBoW(n_vocab, args.unit, loss_func)\n",
        "    \n",
        "else:\n",
        "    raise Exception('Unknown model type: {}'.format(args.model))\n",
        "\n",
        "model.to_device(device)\n",
        "\n",
        "# オプティマイザ設定\n",
        "optimizer = O.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "# 学習イテレータ設定\n",
        "train_iter = WindowIterator(train, args.window, args.batchsize)\n",
        "\n",
        "\n",
        "# アプデータ設定\n",
        "updater = training.updaters.StandardUpdater(\n",
        "    train_iter, optimizer, converter=convert, device=device)\n",
        "\n",
        "# トレーナー設定\n",
        "trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss']))\n",
        "trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "# 学習開始\n",
        "trainer.run()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjO0mN9qxY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vec modelを保存\n",
        "with open('word2vec.model', 'w') as f:\n",
        "    f.write('%d %d\\n' % (len(index2word), args.unit))\n",
        "    w = cuda.to_cpu(model.embed.W.array)\n",
        "    for i, wi in enumerate(w):\n",
        "        v = ' '.join(map(str, wi))\n",
        "        f.write('%s %s\\n' % (index2word[i], v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GesyhM4LzEMu",
        "colab_type": "text"
      },
      "source": [
        "## word2vec.modelの存在を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_djicwTR5gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmVzaZWzL6f",
        "colab_type": "text"
      },
      "source": [
        "## 自分のGoogle Driveに学習済みのword2vec.modelを保存\n",
        "ここでもう一度認証をする必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlztTM9Y49xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr5TBDnN3w8_",
        "colab_type": "code",
        "outputId": "a726c104-ff4b-4f1c-fc32-635225bce98c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'word2vec.model',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('word2vec.model', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1kF-VZKvj7J75eStnNOYm3OQ3ncqHJowG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-0Gdegzgro",
        "colab_type": "text"
      },
      "source": [
        "## 学習済みのword2vec.modelを試してみる\n",
        "下記のコードはGoogle Driveからword2vec.modelをローカルにダウンロードして、test.pyを実行しても良い\n",
        "\n",
        "UserWarningは無視して大丈夫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td_qPsWo44ap",
        "colab_type": "code",
        "outputId": "bd8a79fb-8672-43f9-ec7f-a0d42cacdbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import logging\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "logging.root.setLevel(level=logging.INFO)\n",
        "\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('word2vec.model', binary=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-29 13:01:05,265 : INFO : loading projection weights from word2vec.model\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-08-29 13:02:03,578 : INFO : loaded (361995, 200) matrix from word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdxvI8pC5WBs",
        "colab_type": "code",
        "outputId": "da5676b5-4810-45a3-fb9d-6ae7ec377500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.most_similar(positive=[\"トヨタ\"], topn=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-29 13:02:03,584 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('レクサス', 0.6787608861923218),\n",
              " ('日産', 0.6739553213119507),\n",
              " ('マツダ', 0.6163288354873657),\n",
              " ('フォルクスワーゲン', 0.6144090294837952),\n",
              " ('カワサキ', 0.5994932651519775),\n",
              " ('スバル', 0.592795729637146),\n",
              " ('ダットサン', 0.5844794511795044),\n",
              " ('いすゞ', 0.5839172601699829),\n",
              " ('ホンダ', 0.5827198624610901),\n",
              " ('ブランド', 0.5732850432395935)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXRlL2lrkEd",
        "colab_type": "code",
        "outputId": "599f0161-f15f-4415-aeba-4d9a0fa9e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"声優\"], topn=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ナレーター', 0.6846827268600464),\n",
              " ('俳優', 0.684380292892456),\n",
              " ('脚本家', 0.668969452381134),\n",
              " ('タレント', 0.6612478494644165),\n",
              " ('女優', 0.6289736032485962),\n",
              " ('歌手', 0.622085452079773),\n",
              " ('。声優', 0.6102961897850037),\n",
              " ('演出家', 0.6075438261032104),\n",
              " ('子役', 0.5924990177154541),\n",
              " ('お笑い芸人', 0.5792001485824585)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPathTmH5xji",
        "colab_type": "code",
        "outputId": "c56eab59-a7f2-4930-8af5-dfa53de35441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.most_similar(positive=[\"Python\"], topn=10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('C言語', 0.7438325881958008),\n",
              " ('C++', 0.6913949251174927),\n",
              " ('ライブラリ', 0.6636326313018799),\n",
              " ('プログラミング言語', 0.6612603068351746),\n",
              " ('実装', 0.6601348519325256),\n",
              " ('RPC', 0.6445109248161316),\n",
              " ('Java', 0.6394205093383789),\n",
              " ('MATLAB', 0.6346997022628784),\n",
              " ('NumPy', 0.6321592330932617),\n",
              " ('Mops', 0.6255452036857605)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WhgU1uWfIre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}